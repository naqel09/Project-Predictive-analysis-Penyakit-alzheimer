# -*- coding: utf-8 -*-
"""Alzheimer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K-ptThkFchj5VLSlm2Ig53ayeocqdYkP

# Proyek Machine learning-Andry Septian Syahputra Tumaruk-MC476D5Y0692-MC39

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix,accuracy_score,precision_score,recall_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

"""Pada kode diatas ini kita akan mengimport library yang dibutuhkan untuk menjalankan proyek ini"""

df=pd.read_csv('alzheimers_disease_data.csv')

"""Kode ini digunakan untuk mengimpor dan menampilkan data dari file CSV ke dalam Python menggunakan Pandas. Ini adalah langkah awal dalam proses project ini."""

df.head()

"""kode diatas untuk melihat 5 data paling atas dari dataset

# Explorasi Data Analysisi(EDA)

## Deskripsi variabel
"""

df.info()

"""- Semua kolom memiliki jumlah data lengkap (non-null), artinya tidak ada missing value yang perlu ditangani saat ini.
- Tipe data didominasi oleh float64, kecuali DoctorInCharge yang bertipe integer dan Float.
- Memori yang digunakan cukup ringan, sekitar 587 KB.
"""

df.describe().T

"""- Dataset ini memang fokus pada lansia (kelompok usia risiko Alzheimer). Mayoritas pasien berada antara 60 dan 90 tahun.
- Jumlah pria dan wanita cukup seimbang, sedikit lebih banyak laki-laki.
- Mayoritas pasien memiliki tingkat pendidikan menengah ke atas.
- Rata-rata pasien berada pada kategori overweight menurut standar WHO (BMI > 25).
- Sebagian besar pasien bukan perokok, namun konsumsi alkohol lumayan tersebar.
- Kualitas tidur cenderung baik, tapi aktivitas fisik dan diet perlu ditingkatkan.
- Ada sekelompok pasien dengan penyakit penyerta, yang bisa memperburuk fungsi kognitif.
- Banyak pasien dengan penurunan fungsi kognitif sedang hingga berat.
- Pasien menunjukkan tingkat kemandirian yang menurun.
- Sekitar 33% pasien didiagnosis Alzheimer, sisanya tidak.
"""

df.drop(['PatientID','DoctorInCharge'],inplace=True,axis=1)

"""kode diatas untuk menghapus colom yang tidak ada kaitannya dengan prediksi yang akan kita lakukan

## Menangani missing value
"""

df.isnull().sum()

"""## Menangani data duplikasi"""

print("jumlah data yang terduplikasi:",df.duplicated().sum())

"""kode diatas mengecek duplikasi data yang sedang terjadi

## Univariate analysis
"""

for col in df.columns:
  plt.figure(figsize=(10,5))
  sns.histplot(data=df,x=col,palette='Set1',kde=True)
  plt.xlabel(col)
  plt.title(f"distirbusi data {col}")
  plt.show()

"""melihat distribusi tiap kolom data yang ada

## Multivariate Analysis
"""

plt.figure(figsize=(15,15))
sns.heatmap(df.corr(),annot=True,cmap='coolwarm',fmt=".2f")
plt.title("korelasi antar variabel")

"""kode diatas untuk mengetahui relasi yang terjadi antar kolom dan insight yang kita dapat.

**insight:**
- Gejala kognitif dan perilaku saling berkaitan, misalnya:
 - Forgetfulness, Confusion, MemoryComplaints, dan Disorientation â†’ saling menguatkan.

- Kemampuan fungsional (ADL dan FunctionalAssessment) menunjukkan korelasi tinggi satu sama lain, dan negatif terhadap gangguan perilaku.

- Variabel klinis seperti tekanan darah, kolesterol, dan BMI tidak menunjukkan korelasi kuat dengan variabel lain.
"""

features = df[['Age', 'SystolicBP', 'MMSE', 'PhysicalActivity', 'Diagnosis']]
sns.pairplot(features, hue='Diagnosis' , palette='husl')
plt.suptitle('Simple Pair Plot', y=1.02)
plt.show()

"""- Tidak ada hubungan linier yang jelas antara pasangan variabel (contohnya Age vs MMSE, SystolicBP vs MMSE).

- Namun, dari distribusi MMSE dan Age, kombinasi kedua variabel ini mungkin berguna dalam model prediktif, terutama jika digunakan dalam model non-linier
"""

plt.figure(figsize=(10,6))
sns.lineplot(data=df,x='Age',y='MMSE',hue='Diagnosis',palette='viridis')
plt.title("cognitive score(MMSE) VS AGE")

plt.xlabel('Age')
plt.ylabel('MMSE')
plt.show()

"""**Insight Utama:**
1. Perbedaan Skor MMSE antara Diagnosis 0 dan 1:

 - Pasien dengan Diagnosis = 0 (kemungkinan besar sehat atau non-demensia) memiliki skor MMSE yang konsisten lebih tinggi dibandingkan dengan pasien Diagnosis = 1 (kemungkinan besar menderita demensia atau gangguan kognitif).

 - Ini menunjukkan bahwa kondisi kognitif memang cenderung menurun pada individu yang didiagnosis dengan gangguan kognitif.

2. Variabilitas Skor:

 - Kedua kelompok menunjukkan **fluktuasi skor MMSE** seiring bertambahnya usia, **namun kelompok dengan Diagnosis = 1 menunjukkan variabilitas yang lebih besar**, menandakan ketidakkonsistenan dalam penurunan kognitif, yang bisa disebabkan oleh berbagai faktor klinis.

3. Tren Umum terhadap Usia:

 - Tidak terlihat tren penurunan yang sangat jelas terhadap usia dalam kelompok tertentu, tapi tetap terlihat bahwa pada usia yang sama, kelompok Diagnosis 1 memiliki skor MMSE yang lebih rendah secara konsisten.
"""

plt.figure(figsize=(10,6))
sns.countplot(data=df,x='FamilyHistoryAlzheimers',palette='Set1')
plt.title("family history alzheimers")
plt.xticks([0,1],["Tidak Alzheimers",'Alzheimers'])
plt.legend(title='diagnosis',labels=['tidak alzheirmers','alzheimers'])
plt.show()

"""**1. Mayoritas Pasien Tidak Memiliki Riwayat Keluarga Alzheimer:**

 - Terlihat bahwa jumlah pasien yang tidak memiliki riwayat keluarga Alzheimer jauh lebih banyak (1600) dibandingkan dengan pasien yang memiliki riwayat keluarga Alzheimer (550).

 - Ini menunjukkan bahwa populasi data didominasi oleh individu tanpa riwayat keluarga Alzheimer.

**2. Potensi Hubungan antara Riwayat Keluarga dan Diagnosis Alzheimer:**

 - Meskipun grafik ini tidak langsung membagi berdasarkan diagnosis, tapi adanya riwayat keluarga Alzheimer tetap merupakan faktor risiko yang penting secara klinis.

 - Insight ini bisa diperkuat jika kamu memecahnya berdasarkan Diagnosis, misalnya dengan hue='Diagnosis', sehingga bisa dilihat berapa banyak pasien Alzheimer yang memiliki riwayat keluarga.

# Split data
"""

X=df.drop("Diagnosis",axis=1)
y=df['Diagnosis']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
print("jumlah data pada test:",X_train.shape[0])
print("jumlah data pada test:",X_test.shape[0])

"""kode tersebut dilakukan split data yang dimana data train itu sebesar 80% dan data test itu sebesar 20% dengan jumlah data train dan data test tertera diatas

# scaling data
"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

"""kode tersebut melakukan scaling data dengan menggunakan teknik standarisasi scala

# model development
"""

# model svm
svm=SVC(C=1.0,kernel='linear',gamma=10)
svm.fit(X_train,y_train)
y_pred_svc=svm.predict(X_test)
print(classification_report(y_test,y_pred_svc))

"""**Insight Kinerja Model:**

ðŸ“Œ **1. Akurasi Total Model**

**Accuracy:** 0.82 â†’ artinya, secara keseluruhan model berhasil mengklasifikasikan dengan benar 82% dari data uji.

ðŸ“Œ **2. Kinerja per Kelas**

**Kelas 0 (label: 0):**

- Precision: 0.84 â†’ 84% prediksi kelas 0 benar.

- Recall: 0.89 â†’ dari semua yang sebenarnya kelas 0, 89% berhasil dikenali.

- F1-score: 0.86 â†’ gabungan harmonik precision dan recall menunjukkan kinerja sangat baik untuk kelas 0.

**Kelas 1 (label: 1):**

- Precision: 0.78 â†’ dari seluruh prediksi kelas 1, 78% benar.

- Recall: 0.70 â†’ hanya 70% dari kelas 1 yang benar-benar dikenali â†’ relatif rendah.

- F1-score: 0.74 â†’ kinerja lebih rendah dibanding kelas 0.
"""

# model randomforest
rf=RandomForestClassifier(random_state=42)
rf.fit(X_train,y_train)
y_pred_rf=rf.predict(X_test)
print(classification_report(y_test,y_pred_rf))

"""**Insight Kinerja Model:**

ðŸ“Œ **1. Akurasi Total Model**

**Accuracy:** 0.93 â†’ artinya, secara keseluruhan model berhasil mengklasifikasikan dengan benar 93% dari data uji.

ðŸ“Œ **2. Kinerja per Kelas**

**Kelas 0 (label: 0):**

- Precision: 0.91 â†’ 91% prediksi kelas 0 benar.

- Recall: 0.98 â†’ dari semua yang sebenarnya kelas 0, 98% berhasil dikenali.

- F1-score: 0.94 â†’ gabungan harmonik precision dan recall menunjukkan kinerja sangat baik untuk kelas 0.

**Kelas 1 (label: 1):**

- Precision: 0.96 â†’ dari seluruh prediksi kelas 1, 96% benar.

- Recall: 0.82 â†’ hanya 82% dari kelas 1 yang benar-benar dikenali â†’ relatif rendah.

- F1-score: 0.89 â†’ kinerja lebih rendah dibanding kelas 0.
"""

# model xgboost
xgb=XGBClassifier(use_label_encoder=False,eval_metrics="logloss")
xgb.fit(X_train,y_train)
y_pred_xgb=xgb.predict(X_test)
print(classification_report(y_test,y_pred_xgb))

"""**Akurasi Total Model**

**Accuracy:** 0.95 â†’ artinya, secara keseluruhan model berhasil mengklasifikasikan dengan benar 95% dari data uji.

ðŸ“Œ **Kelas 0 (kemungkinan "tidak Alzheimer")**

- Precision: 0.94 â†’ 94% dari prediksi kelas 0 benar.

- Recall: 0.98 â†’ 98% dari kelas 0 berhasil dikenali.

- F1-score: 0.96 â†’ kombinasi sangat baik antara precision dan recall.

ðŸ“Œ **Kelas 1 (kemungkinan "Alzheimer")**

- Precision: 0.96 â†’ sangat tinggi, model jarang salah mengklasifikasikan kelas 1.

- Recall: 0.90 â†’ 90% dari semua yang benar-benar kelas 1 berhasil dikenali

- F1-score: 0.93 â†’ performa sangat baik dan seimbang.
"""

# menggunakan neural_network
from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(hidden_layer_sizes=(100,50,50),max_iter=1000,activation='relu',solver='adam',learning_rate_init=0.001,batch_size=50,alpha=0.0001)
mlp.fit(X_train,y_train)
y_pred_mlp=mlp.predict(X_test)
print(classification_report(y_test,y_pred_mlp))

"""**Insight Kinerja Model:**

ðŸ“Œ **1. Akurasi Total Model**

**Accuracy:** 0.81 â†’ artinya, secara keseluruhan model berhasil mengklasifikasikan dengan benar 81% dari data uji.

ðŸ“Œ **2. Kinerja per Kelas**

**Kelas 0 (label: 0):**

- Precision: 0.84 â†’ 84% prediksi kelas 0 benar.

- Recall: 0.87 â†’ dari semua yang sebenarnya kelas 0, 87% berhasil dikenali.

- F1-score: 0.85 â†’ gabungan harmonik precision dan recall menunjukkan kinerja sangat baik untuk kelas 0.

**Kelas 1 (label: 1):**

- Precision: 0.75 â†’ dari seluruh prediksi kelas 1, 75% benar.

- Recall: 0.69 â†’ hanya 69% dari kelas 1 yang benar-benar dikenali â†’ relatif rendah.

- F1-score: 0.72 â†’ kinerja lebih rendah dibanding kelas 0.

# evaluasi model

## SVC
"""

sns.heatmap(confusion_matrix(y_test,y_pred_svc),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk SVC model")
plt.show()

"""**Insight:**
- True Negative (246) dan True Positive (107) menunjukkan model mampu mengklasifikasikan banyak data dengan benar.
- False Negative (46) cukup tinggi â†’ model gagal mengenali 46 orang yang seharusnya masuk kategori positif (misalnya, Alzheimer).
- False Positive (31) berarti 31 orang yang sebenarnya sehat diprediksi sebagai sakit, yang bisa menimbulkan kecemasan dan pengujian tambahan yang tidak perlu.
"""

# mengecek apakah datanya overfitting
print("akurasi pada data y_train:",accuracy_score(y_train,svm.predict(X_train)))
print("akurasi pada data y_test:",accuracy_score(y_test,y_pred_svc))

"""- kode diatas untuk mengetahui apakah terjadi overfitting atau underfitting

## Random Forest
"""

sns.heatmap(confusion_matrix(y_test,y_pred_rf),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk RandomForest model")
plt.show()

"""- **Total prediksi benar** = 271 (TN) + 134 (TP) = 398 dari 430

- **False Positive** sangat kecil (5 kasus) â†’ hampir semua pasien sehat diprediksi dengan benar.

- **False Negative** juga rendah (27 kasus) â†’ model cukup sensitif dalam mendeteksi pasien yang benar-benar positif (misalnya Alzheimer).
"""

# mengecak data overfitting
print("akurasi pada data y_train:",accuracy_score(y_train,rf.predict(X_train)))
print("akurasi pada data y_test:",accuracy_score(y_test,y_pred_rf))

"""- kode diatas untuk mengetahui apakah terjadi overfitting atau underfitting

## XGBOOST
"""

sns.heatmap(confusion_matrix(y_test,y_pred_xgb),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk XGBoost model")
plt.show()

"""- **Total prediksi benar** = 270 (TN) + 137 (TP) = 408 dari 430

- **False Positive** sangat kecil (6 kasus) â†’ hampir semua pasien sehat diprediksi dengan benar.

- **False Negative** juga rendah (16 kasus) â†’ model cukup sensitif dalam mendeteksi pasien yang benar-benar positif (misalnya Alzheimer).
"""

# mengecak data overfitting
print("akurasi pada data y_train:",accuracy_score(y_train,xgb.predict(X_train)))
print("akurasi pada data y_test:",accuracy_score(y_test,y_pred_xgb))

"""- kode diatas untuk mengetahui apakah terjadi overfitting atau underfitting

## Multi Layer Perceptron
"""

sns.heatmap(confusion_matrix(y_test,y_pred_mlp),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk MLP model")
plt.show()

"""**Insight:**
- True Negative (241) dan True Positive (106) menunjukkan model mampu mengklasifikasikan banyak data dengan benar.
- False Negative (47) cukup tinggi â†’ model gagal mengenali 47 orang yang seharusnya masuk kategori positif (misalnya, Alzheimer).
- False Positive (36) berarti 36 orang yang sebenarnya sehat diprediksi sebagai sakit, yang bisa menimbulkan kecemasan dan pengujian tambahan yang tidak perlu.

# optimasi model
"""

svc_param_grid={
    'C':[1],
    'gamma':[1,0.1],
    'kernel':['linear']
}

# MENGGUNAKAN GRID SEARCH
from sklearn.model_selection import GridSearchCV
grid_svc=GridSearchCV(SVC(),svc_param_grid,refit=True,verbose=1)
grid_svc.fit(X_train,y_train)
print("parameter terbaik adalah:",grid_svc.best_estimator_)

"""kode diatas untuk melakukan optimasi terhadap model SVC untuk mencari parameter terbaik dengan melakukan grid search"""

rf_param_grid={
    'min_samples_split':[5,10],
    'max_features':['log2'],
    'bootstrap':[False]
}

# MENGGUNAKAN GRID SEARCH
grid_rf=GridSearchCV(RandomForestClassifier(),rf_param_grid,refit=True,verbose=1)
grid_rf.fit(X_train,y_train)
print("parameter terbaik adalah:",grid_rf.best_estimator_)

"""kode diatas untuk melakukan optimasi terhadap model Random Forest untuk mencari parameter terbaik dengan melakukan grid search"""

xgboost_param_grid={
    'n_estimators':[200],
    'learning_rate':[0.01],
    'max_depth':[3,5],
    'colsample_bytree':[1.0],
    'gamma':[0]
}

# MENGGUNAKAN GRID SEARCH
grid_xgb=GridSearchCV(XGBClassifier(),xgboost_param_grid,refit=True,verbose=1)
grid_xgb.fit(X_train,y_train)
print("parameter terbaik adalah:",grid_xgb.best_estimator_)

"""kode diatas untuk melakukan optimasi terhadap model XGBoost untuk mencari parameter terbaik dengan melakukan grid search"""

mlp_param_grid={
    'hidden_layer_sizes':[(50,50,50)],
    'learning_rate_init':[0.001,0.01],
    'batch_size':[100],
    'alpha':[0.0]
}
# MENGGUNUNAKAN GRID SEARCH
grid_mlp=GridSearchCV(MLPClassifier(),mlp_param_grid,refit=True,verbose=1)
grid_mlp.fit(X_train,y_train)
print("parameter terbaik adalah:",grid_mlp.best_estimator_)

"""kode diatas untuk melakukan optimasi terhadap model XGBoost untuk mencari parameter terbaik dengan melakukan grid search

# Evaluasi Model Setelah Melakukan Optimasi
"""

# model svm
svm=SVC(C=1.0,kernel='linear',gamma=1)
svm.fit(X_train,y_train)
y_pred_svc=svm.predict(X_test)
print(classification_report(y_test,y_pred_svc))

sns.heatmap(confusion_matrix(y_test,y_pred_svc),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk SVC model")
plt.show()

# model randomforest
rf=RandomForestClassifier(bootstrap=False, max_features='log2',
                       min_samples_split=10,random_state=42)
rf.fit(X_train,y_train)
y_pred_rf=rf.predict(X_test)
print(classification_report(y_test,y_pred_rf))

sns.heatmap(confusion_matrix(y_test,y_pred_rf),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk RandomForest model")
plt.show()

# Model XGBOOST
xgb=XGBClassifier(colsample_bytree=1.0,gamma=0,learning_rate=0.01,max_depth=5,n_estimators=200,use_label_encoder=False,eval_metrics="logloss")
xgb.fit(X_train,y_train)
y_pred_xgb=xgb.predict(X_test)
print(classification_report(y_test,y_pred_xgb))

sns.heatmap(confusion_matrix(y_test,y_pred_xgb),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk XGBoost model")
plt.show()

# menggunakan neural_network
from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(hidden_layer_sizes=(50,50,50),max_iter=600,activation='relu',solver='adam',learning_rate_init=0.01,batch_size=100,alpha=0.0)
mlp.fit(X_train,y_train)
y_pred_mlp=mlp.predict(X_test)
print(classification_report(y_test,y_pred_mlp))

sns.heatmap(confusion_matrix(y_test,y_pred_mlp),annot=True,fmt="d")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("confusion matrix untuk MLP model")
plt.show()

"""# Insight:
setiap optimasi yang dilakukan untuk setiap-setiap model tidak ada perubahan yang akurasi signifikan yang terjadi baik itu SVC,RandomForestClassifier,XGBOOST,dan MLPClassifier itu tidak ada perubahan baik sebelum optimasi dan setelah optimasi

# Tabel Perbandingan
"""

# membuat tabel perbandingan menggunakan pandas
from sklearn.metrics import f1_score
tabel_perbandingan=pd.DataFrame({
    "model":["SVC","RandomForest","XGBoost","MLP"],
    "akurasi":[accuracy_score(y_test,y_pred_svc),accuracy_score(y_test,y_pred_rf),accuracy_score(y_test,y_pred_xgb),accuracy_score(y_test,y_pred_mlp)],
    "precision":[precision_score(y_test,y_pred_svc),precision_score(y_test,y_pred_rf),precision_score(y_test,y_pred_xgb),precision_score(y_test,y_pred_mlp)],
    "recall":[recall_score(y_test,y_pred_svc),recall_score(y_test,y_pred_rf),recall_score(y_test,y_pred_xgb),recall_score(y_test,y_pred_mlp)],
    "f1-score":[f1_score(y_test,y_pred_svc),f1_score(y_test,y_pred_rf),f1_score(y_test,y_pred_xgb),f1_score(y_test,y_pred_mlp)]
})

tabel_perbandingan

"""ðŸ“Œ **Perbandingan Model:**
1. **XGBoost:**

- Memiliki skor tertinggi hampir di semua metrik:

 - Akurasi: 95.35%

 - Precision: 95.24%

 - Recall: 91.50%

 - F1-score: 93.33%

**Kesimpulan**: XGBoost adalah model dengan performa terbaik secara keseluruhan.

2. **RandomForest:**

- Performa sangat baik juga, meskipun sedikit di bawah XGBoost:

 - Akurasi: 94.19%

 - Precision: 95.71% (bahkan lebih tinggi dari XGBoost)

 - Recall: 87.58%

 - F1-score: 91.47%

**Kesimpulan:** Sangat baik, terutama jika ingin memaksimalkan precision.

3. **SVC (Support Vector Classifier):**

 - Performa sedang:

 - Akurasi: 82.09%

 - F1-score: 73.54%

 - Precision dan recall relatif seimbang, namun lebih rendah dari RandomForest dan XGBoost.

**Kesimpulan:** Layak, tapi kalah jauh dari dua model di atas.

4. **MLP (Multilayer Perceptron):**

- Performa terendah di semua metrik:

 - Akurasi: 80.47%

 - Precision: 74.13%

 - Recall: 69.28%

 - F1-score: 71.62%

**Kesimpulan:** MLP kurang efektif untuk kasus ini dibanding model lainnya.
"""

